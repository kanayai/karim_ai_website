[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my research blog. Here I share my thoughts on AI, Data Science, and more.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodological Rigor: A Reproducibility Guide for Computational Science\n\n\n\n\n\n\n\n\n10/12/2025\n\n\n\n\n\n\n\n\n\n\n\n\nGit vs.¬†OneDrive: The Data Scientist‚Äôs Guide\n\n\n\ngit\n\nworkflow\n\ndata-science\n\n\n\nA guide on how to manage data science projects using both Git and OneDrive effectively.\n\n\n\n\n\n28/11/2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Academic Workflow\n\n\n\nworkflow\n\nacademic\n\ngit\n\nonedrive\n\n\n\nA master guide to managing Teaching, Research, and Code across multiple computers.\n\n\n\n\n\n28/11/2025\n\n\n\n\n\n\n\n\n\n\n\n\nAnscombe‚Äôs quartet\n\n\n\ntutorial\n\npython\n\n\n\nThis is a short summary of the post that will appear in the blog list and on the card.\n\n\n\n\n\n15/11/2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/academic_workflow.html",
    "href": "posts/academic_workflow.html",
    "title": "The Academic Workflow",
    "section": "",
    "text": "As academic data scientists, we juggle three distinct types of work: Teaching (slides, quizzes), Research (papers, heavy analysis), and Administration.\nIf you work across multiple machines‚Äîsay, a powerful Office Desktop and a personal Laptop‚Äîyou face a dilemma: Cloud storage (OneDrive/Dropbox) is great for PDFs but ruins code history. Git is perfect for code but chokes on 2GB datasets.\nHere is the ‚ÄúMirrored Architecture‚Äù to handle it all effortlessly."
  },
  {
    "objectID": "posts/academic_workflow.html#the-setup-where-to-create-your-folders",
    "href": "posts/academic_workflow.html#the-setup-where-to-create-your-folders",
    "title": "The Academic Workflow",
    "section": "1. The Setup: Where to create your folders",
    "text": "1. The Setup: Where to create your folders\nBefore we talk about Git, we must talk about Location. Most modern Operating Systems try to ‚Äúhelp‚Äù you by syncing your Documents folder to the cloud automatically (iCloud on Mac, OneDrive on Windows).\n\n\n\n\n\n\nWarningThe ‚ÄúDocuments‚Äù Trap\n\n\n\nDo NOT put your Git repositories inside your Documents folder. If iCloud/OneDrive syncs a file while Git is writing to it, your repository can become corrupted.\n\n\nYou need to create a dedicated Projects folder at your ‚ÄúUser Root‚Äù (Home) level, sitting side-by-side with your Cloud folder.\n\n\nüçé macOS 1. Go to Finder. 2. Press Cmd + Shift + H (Go to Home). 3. Create a folder named Projects. 4. Drag it to your Sidebar favorites.\nPath: /Users/yourname/Projects\n\n\nü™ü Windows 1. Open File Explorer. 2. Go to C:\\Users\\YourName. 3. Create a folder named Projects. 4. Right-click -&gt; ‚ÄúPin to Quick Access‚Äù.\nPath: C:\\Users\\yourname\\Projects\n\n\nüêß Linux 1. Open Terminal. 2. Type mkdir ~/Projects. 3. You‚Äôre done.\nPath: /home/yourname/Projects"
  },
  {
    "objectID": "posts/academic_workflow.html#the-architecture-mirrored-roots",
    "href": "posts/academic_workflow.html#the-architecture-mirrored-roots",
    "title": "The Academic Workflow",
    "section": "2. The Architecture: Mirrored Roots",
    "text": "2. The Architecture: Mirrored Roots\nNow that you have your locations set, follow the Mirrored Strategy. You will have two root folders. They will have identical sub-folder structures, but they serve different purposes.\n\n\n\n\nüíª ~/Projects (Local + Git)\n\n\n\n\nüìÇ Teaching/\n\n\nüìÇ ma101_linear_algebra/\n\n\nüìÑ lectures.qmd\n\n\nüìÑ script_week1.R\n\n\nüìÑ _quarto.yml\n\n \n\nüìÇ Research/\n\n\nüìÇ climate_change_paper/\n\n\nüìÑ analysis.ipynb\n\n\nüìÑ manuscript.tex\n\n\n\nRule: Contains Text & Code only. No large files (&gt;50MB). This is backed up via GitHub.\n\n\n\n\n\n‚òÅÔ∏è ~/OneDrive (Synced)\n\n\n\n\nüìÇ Teaching/\n\n\nüìÇ ma101_linear_algebra/\n\n\nüìÑ scanned_textbook.pdf\n\n\nüìÑ student_grades.xlsx\n\n \n\nüìÇ Research/\n\n\nüìÇ climate_change_paper/\n\n\nüìÑ raw_weather_data.csv (2GB)\n\n\nüìÑ final_proof.pdf\n\n\n\nRule: Contains Binaries, Data, and PDFs. Accessible from anywhere (web/phone)."
  },
  {
    "objectID": "posts/academic_workflow.html#the-automation-one-script-to-rule-them-all",
    "href": "posts/academic_workflow.html#the-automation-one-script-to-rule-them-all",
    "title": "The Academic Workflow",
    "section": "3. The Automation: One Script to Rule Them All",
    "text": "3. The Automation: One Script to Rule Them All\nWhen you have 10+ active repositories, you cannot manually git pull inside every folder. You need a ‚ÄúMaster Loop‚Äù script.\n#!/bin/bash\n# üíæ Save this as: sync_work.sh\n# ---------------------------------------------------------\n# Define where your Git Projects live (Not OneDrive paths!)\n# ---------------------------------------------------------\nTARGET_DIRS=(\n    \"$HOME/Projects/Teaching\"\n    \"$HOME/Projects/Research\"\n)\n\necho \"üîÑ MASTER SYNC INITIATED...\"\n\n# Function to handle a single repository\nsync_repo() {\n    local repo_path=\"$1\"\n    local name=$(basename \"$repo_path\")\n    cd \"$repo_path\" || return\n\n    # Check if it's actually a git repo\n    if [ ! -d \".git\" ]; then return; fi\n\n    echo -e \"\\nüìÇ Processing: $name\"\n\n    # 1. ADD & COMMIT (Save your work)\n    git add .\n    if ! git diff-index --quiet HEAD --; then\n        timestamp=$(date \"+%Y-%m-%d %H:%M\")\n        git commit -m \"Auto-Sync: $(hostname) at $timestamp\" --quiet\n        echo \"   üíæ Local changes committed.\"\n    fi\n\n    # 2. PULL (Get work from other computers)\n    # We use --rebase to keep history clean (linear)\n    if git pull --rebase origin main --quiet; then\n        echo \"   ‚¨áÔ∏è  Pulled latest changes.\"\n    else\n        echo \"   ‚ùå CONFLICT DETECTED. Please resolve manually.\"\n        return 1\n    fi\n\n    # 3. PUSH (Upload your work)\n    if git push origin main --quiet; then\n        echo \"   ‚¨ÜÔ∏è  Pushed to GitHub.\"\n    else\n        echo \"   ‚ùå Push failed. Check internet connection.\"\n    fi\n}\n\n# MAIN LOOP\n# Find all subdirectories in your target folders and sync them\nfor parent in \"${TARGET_DIRS[@]}\"; do\n    if [ -d \"$parent\" ]; then\n        for d in \"$parent\"/*/; do\n            sync_repo \"${d%/}\"\n        done\n    fi\ndone\n\necho -e \"\\nüéâ Sync Complete! Safe to switch computers.\"\nMac/Linux Users: Run chmod +x sync_work.sh to make it executable. Windows Users: Install ‚ÄúGit Bash‚Äù (included with Git for Windows) to run this script."
  },
  {
    "objectID": "posts/academic_workflow.html#connecting-the-worlds-how-to-load-data",
    "href": "posts/academic_workflow.html#connecting-the-worlds-how-to-load-data",
    "title": "The Academic Workflow",
    "section": "4. Connecting the Worlds: How to Load Data",
    "text": "4. Connecting the Worlds: How to Load Data\nYour code is in ~/Projects, but your data is in ~/OneDrive. How do you load the data without hardcoding paths that break when you switch computers?\n\nMethod A: For Small Data (Inside Git)\nIf your data is small (&lt;50MB) and lives inside your project folder, use Project-Relative Paths. This guarantees your code runs anywhere.\nUsing R‚Äôs here package\nlibrary(here) \n# 'here()' automatically finds the root of your Git project\n# No more setwd()! \ndf &lt;- read.csv(here(\"data\", \"small_dataset.csv\"))\nUsing Python‚Äôs pyprojroot\nimport pandas as pd\nfrom pyprojroot import here\n\n# Finds the root containing .git, requirements.txt, etc.\n# The '/' operator works because here() returns a Path object\ndata_path = here() / \"data\" / \"small_dataset.csv\"\ndf = pd.read_csv(data_path)\n\n\nMethod B: For Large Data (In OneDrive/Cloud)\nFor data that lives outside the project (in the cloud), paths might differ per machine (e.g., OneDrive - University vs OneDrive - Personal). The professional solution is Environment Variables.\n\nCreate a hidden file in your Home folder containing the path for that specific computer.\n\nüìÑ .Renviron (Save in your Home folder)\n# On your Work Computer\nCLOUD_DATA_DIR=\"/Users/admin/OneDrive - University/Research\"\n\n# On your Home Computer\nCLOUD_DATA_DIR=\"/Users/john/OneDrive/Research\"\n\nLoad it in your code using the variable name. The code remains identical on both machines!\n\nIn R (Automatic Loading)\n# R automatically reads .Renviron on startup\ndata_root &lt;- Sys.getenv(\"CLOUD_DATA_DIR\")\n\ndf &lt;- read.csv(file.path(data_root, \"climate_change_paper\", \"big_data.csv\"))\nIn Python (Using dotenv)\nimport os\nimport pandas as pd\nfrom dotenv import load_dotenv\n\n# Load variables from .env or .Renviron file\nload_dotenv() \n\ndata_root = os.getenv(\"CLOUD_DATA_DIR\")\ndf = pd.read_csv(f\"{data_root}/climate_change_paper/big_data.csv\")"
  },
  {
    "objectID": "posts/academic_workflow.html#summary-checklist",
    "href": "posts/academic_workflow.html#summary-checklist",
    "title": "The Academic Workflow",
    "section": "Summary Checklist",
    "text": "Summary Checklist\n\nLocation: Move all code to ~/Projects. Move all docs to ~/OneDrive.\nStructure: Keep separate folders for Teaching and Research inside both locations.\nAutomate: Run the sync script when you sit down (Pull) and when you stand up (Push).\nPaths: Use here() for repo files and Sys.getenv() for cloud files."
  },
  {
    "objectID": "posts/git-vs-onedrive.html",
    "href": "posts/git-vs-onedrive.html",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "",
    "text": "Read Time: ~8 Minutes\nAs Data Scientists using Mac, Windows, or Linux, we live in two worlds. We deal with massive datasets (perfect for Cloud Storage) and version-dependent code (perfect for Git).\nDeciding where to store a project can be confusing. Make the wrong choice, and you end up with corrupted repositories or lost versions. This guide breaks down exactly where your files belong."
  },
  {
    "objectID": "posts/git-vs-onedrive.html#the-decision-matrix-what-goes-where",
    "href": "posts/git-vs-onedrive.html#the-decision-matrix-what-goes-where",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "1. The Decision Matrix: What Goes Where?",
    "text": "1. The Decision Matrix: What Goes Where?\nThe fundamental difference is simple: OneDrive syncs the ‚ÄúNow‚Äù (making folders identical across devices), while GitHub tracks the ‚ÄúHistory‚Äù (how a file evolved line-by-line).\n\n\n\n\n\n\nTipüß™ The ‚ÄúNotepad Test‚Äù (Rule of Thumb)\n\n\n\nOpen your file in a basic text editor (Notepad/TextEdit).\n\nCan you read it? (Python script, Markdown, CSV) ‚Üí Use GitHub.\nDoes it look like alien gibberish? (PDF, Excel, .pkl, .exe) ‚Üí Use OneDrive.\n\n\n\n\n\n\n\n\n\n\n\nFeature\nOneDrive / Dropbox\nGitHub / GitLab\n\n\n\n\nBest For\nFinal Results, Documents, Images\nSource Code, Configs, Text\n\n\nFile Types\nBinary (.docx, .pdf, .jpg, .zip)\nPlain Text (.py, .R, .md, .tex)\n\n\nData Size\nGreat for Large Data (&gt;100MB)\nPoor for large files (Keep repo &lt; 1GB)\n\n\nConflict Handling\nCreates ‚ÄúConflicted Copy‚Äù files\nManual line-by-line merge"
  },
  {
    "objectID": "posts/git-vs-onedrive.html#the-mirrored-workflow-recommended",
    "href": "posts/git-vs-onedrive.html#the-mirrored-workflow-recommended",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "2. The ‚ÄúMirrored‚Äù Workflow (Recommended)",
    "text": "2. The ‚ÄúMirrored‚Äù Workflow (Recommended)\nFor research and data science, you shouldn‚Äôt choose one or the other. You need both, but they must remain separate.\n\n\n\n\n\nflowchart LR\n    Git[\"üíª Local Folder (Git)\n    ~/Projects/analysis\n    (Scripts, Reports, Configs)\"] \n    \n    Cloud[\"‚òÅÔ∏è Cloud Storage\n    ~/OneDrive/Data\n    (Raw CSVs, Large Zips, Final PDFs)\"]\n\n    Git &lt;--&gt;|\"Linked via Code\"| Cloud\n\n    style Git stroke:#2563eb,stroke-width:2px,fill:#fff,color:#333\n    style Cloud stroke:#f59e0b,stroke-width:2px,fill:#fff,color:#333\n\n\n\n\n\n\n\nHow to link them safely (Mac/Win/Linux safe)\nUse code that detects your OS automatically so you don‚Äôt have to change paths when switching from Mac to Windows.\nR Example:\n# path.expand(\"~\") finds C:/Users/Name (Win) or /Users/Name (Mac)\ndata_path &lt;- file.path(path.expand(\"~\"), \"OneDrive\", \"Research\", \"data.csv\")\ndf &lt;- read.csv(data_path)\nPython Example:\nfrom pathlib import Path\nimport pandas as pd\n\n# Path.home() is the universal way to find the user folder\ndata_path = Path.home() / \"OneDrive\" / \"Research\" / \"data.csv\"\ndf = pd.read_csv(data_path)"
  },
  {
    "objectID": "posts/git-vs-onedrive.html#the-danger-zone-git-inside-onedrive",
    "href": "posts/git-vs-onedrive.html#the-danger-zone-git-inside-onedrive",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "3. The Danger Zone: Git INSIDE OneDrive",
    "text": "3. The Danger Zone: Git INSIDE OneDrive\n\n\n\n\n\n\nImportant‚ö†Ô∏è CRITICAL WARNING\n\n\n\nNever initialize a Git repository inside a synced OneDrive/Dropbox/iCloud folder.\n\n\nWhy? Sync clients (OneDrive) and Version Control (Git) fight over the hidden .git folder. This leads to:\n\nRepo Corruption: OneDrive may ‚Äúsync‚Äù a file lock that Git needs.\nConflicted Copies: You will end up with files named script.py (Computer Name Conflicted Copy)."
  },
  {
    "objectID": "posts/git-vs-onedrive.html#how-to-fix-it-moving-out-of-onedrive",
    "href": "posts/git-vs-onedrive.html#how-to-fix-it-moving-out-of-onedrive",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "4. How to Fix It (Moving Out of OneDrive)",
    "text": "4. How to Fix It (Moving Out of OneDrive)\nIf your project is currently stuck in OneDrive, follow these steps. Do NOT move it to ‚ÄúDocuments‚Äù (as Documents often auto-syncs to Cloud too).\n\nStep 0: Create a Safe ‚ÄúProjects‚Äù Folder\n\nüçé macOS: Create /Users/name/Projects (Do not put in Documents!)\nü™ü Windows: Create C:\\Users\\name\\Projects (Do not put in Documents!)\nüêß Linux: Create /home/name/Projects (Safe anywhere in ~)\n\n\n\nStep 1: On Your Primary Computer\n\nMove the Folder: Drag your project folder OUT of OneDrive and into your new Projects folder.\nVerify: Open your terminal (Git Bash on Windows).\ncd ~/Projects/my-project\ngit status\nCleanup: Check OneDrive. If a copy remains there, delete it to stop the sync confusion.\n\n\n\nStep 2: On Your Secondary Computer\nDo not try to ‚Äúfix‚Äù the existing folder on your second computer. It‚Äôs faster to start fresh.\n\nLet OneDrive Sync: Wait for OneDrive to update. It should automatically remove the old folder.\nClone Fresh: Download a clean connection to GitHub in your safe local folder.\ncd ~/Projects\ngit clone https://github.com/yourname/my-project.git"
  },
  {
    "objectID": "posts/git-vs-onedrive.html#summary",
    "href": "posts/git-vs-onedrive.html#summary",
    "title": "Git vs.¬†OneDrive: The Data Scientist‚Äôs Guide",
    "section": "Summary",
    "text": "Summary\n\nCode lives in ~/Projects (Git).\nData lives in ~/OneDrive (Cloud).\nNever put Git inside OneDrive or Documents (if synced).\n\n\nThis post was created with the help of Gemini."
  },
  {
    "objectID": "posts/anscombe_quartet.html",
    "href": "posts/anscombe_quartet.html",
    "title": "Anscombe‚Äôs quartet",
    "section": "",
    "text": "So, I am learning how to use ggplot. Here is one my first attempts and at the same time I discover that you need to use the gridExtra package to layout multiople ggplots. I am using one of my favourite datasets: the Anscombe quartet\n\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(gridExtra)\n\ndata(anscombe)\n\nThe quartet comprises four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed.\n\np1&lt;-ggplot(anscombe,aes(x1,y1))+geom_point()+geom_smooth(method=\"lm\",se=FALSE,color=\"red\")+xlim(3,16)\np2&lt;-ggplot(anscombe,aes(x2,y2))+geom_point()+geom_smooth(method=\"lm\",se=FALSE,color=\"red\")+xlim(3,16)\np3&lt;-ggplot(anscombe,aes(x3,y3))+geom_point()+geom_smooth(method=\"lm\",se=FALSE,color=\"red\")+xlim(3,16)\np4&lt;-ggplot(anscombe,aes(x4,y4))+geom_point()+geom_smooth(method=\"lm\",se=FALSE,color=\"red\")+xlim(7,20)\n\ngrid.arrange(p1,p2,p3,p4,ncol=2)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe can see that the fitted lines are actually almost identical since the summary statistics are almost identical as well.\n\ncoefficients(lm(y1~x1,anscombe))\n\n(Intercept)          x1 \n  3.0000909   0.5000909 \n\ncoefficients(lm(y2~x2,anscombe))\n\n(Intercept)          x2 \n   3.000909    0.500000 \n\ncoefficients(lm(y3~x3,anscombe))\n\n(Intercept)          x3 \n  3.0024545   0.4997273 \n\ncoefficients(lm(y4~x4,anscombe))\n\n(Intercept)          x4 \n  3.0017273   0.4999091"
  },
  {
    "objectID": "posts/reproducibility_guide.html",
    "href": "posts/reproducibility_guide.html",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "",
    "text": "As research enters the age of ‚ÄúScientific Machine Learning,‚Äù the boundary between code and theory is blurring. We treat our scripts as lab notebooks, but unlike a physical notebook, code mutates.\nThe Scenario: It is six months after your conference submission, or perhaps two weeks before your thesis defense. - The PI: ‚ÄúCan you regenerate Figure 3b with slightly thicker linewidths?‚Äù - The Student: Panic. The code has evolved. The parameters used for Chapter 4 are lost. The random seed is forgotten.\nOr consider the ‚Äú10-Year Test‚Äù: A decade from now, a researcher (or your future self) asks: ‚ÄúIn Table 6d of your 2025 paper, the variance seems surprisingly low. How exactly was that derived?‚Äù Without a snapshot of the code and parameters, that question is unanswerable.\nThis post outlines a concrete ‚ÄúGold Standard‚Äù for Reproducibility in academic data science, tailored for students and researchers working with stochastic simulations (MCMC, Molecular Dynamics)."
  },
  {
    "objectID": "posts/reproducibility_guide.html#the-gold-standard-of-provenance",
    "href": "posts/reproducibility_guide.html#the-gold-standard-of-provenance",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "1. The ‚ÄúGold Standard‚Äù of Provenance",
    "text": "1. The ‚ÄúGold Standard‚Äù of Provenance\nReproducibility isn‚Äôt just about saving your code. It‚Äôs about linking a specific result to the specific state of the code that produced it.\n\nGit Commit Tracking\nThis is the single most important step. Your outputs should know where they came from.\nBad Practice: Naming folders results_final_final_v2.\nBest Practice: Automatically logging the Git commit hash with every output.\nIn Python, you can grab this dynamically:\nimport subprocess\n\ndef get_git_hash():\n    return subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode('ascii').strip()\nR users can achieve the same:\nget_git_hash &lt;- function() {\n  system(\"git rev-parse HEAD\", intern = TRUE)\n}\nWhen my analysis script runs, it writes a config_log.md file into the results folder that says: &gt; ‚ÄúThis result was generated using code version a1b2c3d.‚Äù\n\nNew to Version Control? Do not rely on local backups. Publishing code to a remote repository is standard practice for Open Science. If you are new to GitHub, start with the GitHub Hello World Guide or GitLab Basics.\n\n\n\nConfiguration Logging\nCode defines logic; configuration defines parameters. Both change.\nNever hardcode parameters (like material constants or hyperparameters) inside your functions. Isolate them in a config object (dictionary or JSON) and dump this entire config to your log file alongside the results."
  },
  {
    "objectID": "posts/reproducibility_guide.html#taming-randomness",
    "href": "posts/reproducibility_guide.html#taming-randomness",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "2. Taming Randomness",
    "text": "2. Taming Randomness\nStochastic simulations (like MCMC or Molecular Dynamics) are notorious for ‚Äúit worked once.‚Äù\n\nThe Seed Problem\nComputers cannot generate ‚Äútrue‚Äù random numbers. They use Pseudo-Random Number Generators (PRNGs), which are essentially reading from a fixed, pre-calculated list of numbers. The ‚Äúseed‚Äù tells the computer which page of that book to start reading from. - Seed 0: Starts at page 0 (Sequence: 0.12, 0.88‚Ä¶) - Seed 999: Starts at page 999 (Sequence: 0.76, 0.02‚Ä¶)\nIf you don‚Äôt fix the seed, the computer picks a random page based on the current time (nanoseconds). This means your simulation takes a completely different ‚Äúrandom walk‚Äù every time you run it, making digit-for-digit reproducibility impossible.\nThe ‚ÄúHidden Seed‚Äù Trap: A common mistake is hardcoding the seed deep in a script where it‚Äôs invisible to your logs.\n\nBad (Hidden): rng_key = random.PRNGKey(0) inside main.py. Your log just says ‚ÄúModel A ran‚Äù, but doesn‚Äôt say how.\nGood (Visible): config = {\"seed\": 0, ...}. Your script reads config['seed'], and your log dumps the entire config. Now the seed is explicitly recorded forever.\n\n\n\nThe JAX/NumPyro Solution\nModern frameworks like JAX use explicit key passing. You don‚Äôt set a state; you split a key.\nrng_key = random.PRNGKey(0)\nrng_key, subkey = random.split(rng_key)\nresult = run_simulation(subkey)\n\n\nOther Solutions\nIf you aren‚Äôt using JAX, you can still achieve this. - NumPy (Modern): Use numpy.random.Generator. Pass the rng object explicitly to functions, rather than relying on np.random. python     rng = np.random.default_rng(seed=42)     val = rng.normal() - Rule of Thumb: Avoid global state. Explicitly pass your source of randomness.\n\nFor R Users\nR relies heavily on global state (set.seed()). To maintain rigor: - Script-Level: Call set.seed(123) at the very top of your main script. - Function-Level: Use withr::with_seed() to isolate randomness within functions. r     withr::with_seed(42, {       run_simulation()     })"
  },
  {
    "objectID": "posts/reproducibility_guide.html#data-hygiene-preprocessing-as-code",
    "href": "posts/reproducibility_guide.html#data-hygiene-preprocessing-as-code",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "3. Data Hygiene: Preprocessing as Code",
    "text": "3. Data Hygiene: Preprocessing as Code\nA common trap is manual data manipulation.\nScenario: You have experimental data. You open Excel, delete the rows where the load is negative, truncate the data at 10mm extension because ‚Äúit looked noisy,‚Äù and save it as clean_data.csv.\nThe Problem: That logic is now lost. No one (including you) knows exactly how the data was cleaned.\nThe Solution: Preprocessing as Code.\n\nLoad Raw: Always load the untouched original file.\nFilter in Code:\n    # Explicit filtering\n    data = data[data['load'] &gt; 0]  # Remove negatives\n    data = data[data['extension'] &lt; max_limit]  # Truncate\n    ```\n\n*R (tidyverse) equivalent:*\n```r\ndata &lt;- raw_data %&gt;%\n  filter(load &gt; 0, extension &lt; max_limit)\nSplit Logic: If you analyze ‚ÄúShear‚Äù vs ‚ÄúNormal‚Äù data, writing logic to split them based on column names or clean rules is better than manually moving files into folders."
  },
  {
    "objectID": "posts/reproducibility_guide.html#environment-sanity",
    "href": "posts/reproducibility_guide.html#environment-sanity",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "4. Environment Sanity",
    "text": "4. Environment Sanity\nFinally, your code lives in an ecosystem. Python 3.9 might round a float differently than Python 3.11.\nUse dependency management tools that support lockfiles. - uv (current favorite): extremely fast, strictly locks dependencies. - poetry: reliable standard.\nFor R Users: - renv: The standard for R dependency management. It creates an renv.lock file that serves the exact same purpose.\nA uv.lock or poetry.lock file ensures that numpy==1.24.3 is used today, tomorrow, and by the person trying to replicate your work next year."
  },
  {
    "objectID": "posts/reproducibility_guide.html#the-reproduction-recipe",
    "href": "posts/reproducibility_guide.html#the-reproduction-recipe",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "5. The ‚ÄúReproduction Recipe‚Äù",
    "text": "5. The ‚ÄúReproduction Recipe‚Äù\nOnce you have these pillars in place, how does someone (or you) actually reproduce the work?\n\nCheckout the Code: Use the Git Hash logged in your results. git checkout &lt;commit_hash&gt;\nRestore the Environment: Use your lockfile. uv sync\nLoad the Config: Take the JSON dump from your config_log.md and use it as the input.\nRun: Execute the script.\n\nBecause you controlled the Code (Git), Parameters (Config), Randomness (Seeds), and Environment (Lockfile), you will get the exact same table 6d."
  },
  {
    "objectID": "posts/reproducibility_guide.html#summary-toward-open-science",
    "href": "posts/reproducibility_guide.html#summary-toward-open-science",
    "title": "Methodological Rigor: A Reproducibility Guide for Computational Science",
    "section": "Summary: Toward ‚ÄúOpen Science‚Äù",
    "text": "Summary: Toward ‚ÄúOpen Science‚Äù\nReproducibility is defensive research. You are defending your future self against confusion‚Äîand ensuring you can graduate without a last-minute crisis.\n\nLog the Commit Hash (Version Control).\nDump the Config (Parameter Tracking).\nLog the Seed (Stochastic Determinism).\nCodify Data Compiling (Transparent Methodologies).\nLock your Environment (Dependency Rigor).\n\nImplementing these steps moves your work from ‚Äúrunnable scripts‚Äù to robust, citeable scientific artifacts‚Äîthe kind that get papers accepted and theses approved."
  }
]