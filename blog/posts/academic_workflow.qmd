---
title: "The Academic Workflow"
date: "2025-11-28"
categories: [workflow, academic, git, onedrive]
description: "A master guide to managing Teaching, Research, and Code across multiple computers."
format:
  html:
    toc: true
---

As academic data scientists, we juggle three distinct types of work: **Teaching** (slides, quizzes), **Research** (papers, heavy analysis), and **Administration**.

If you work across multiple machinesâ€”say, a powerful Office Desktop and a personal Laptopâ€”you face a dilemma: Cloud storage (OneDrive/Dropbox) is great for PDFs but ruins code history. Git is perfect for code but chokes on 2GB datasets.

Here is the "Mirrored Architecture" to handle it all effortlessly.

## 1. The Setup: Where to create your folders

Before we talk about Git, we must talk about **Location**. Most modern Operating Systems try to "help" you by syncing your `Documents` folder to the cloud automatically (iCloud on Mac, OneDrive on Windows).

::: {.callout-warning}
#### The "Documents" Trap
Do **NOT** put your Git repositories inside your `Documents` folder. If iCloud/OneDrive syncs a file while Git is writing to it, your repository can become corrupted.
:::

You need to create a dedicated **Projects** folder at your "User Root" (Home) level, sitting side-by-side with your Cloud folder.

::: {.os-grid}
::: {.os-card}
**ğŸ macOS**
1. Go to Finder.<br>
2. Press `Cmd + Shift + H` (Go to Home).<br>
3. Create a folder named `Projects`.<br>
4. Drag it to your Sidebar favorites.

*Path: `/Users/yourname/Projects`*
:::
::: {.os-card}
**ğŸªŸ Windows**
1. Open File Explorer.<br>
2. Go to `C:\Users\YourName`.<br>
3. Create a folder named `Projects`.<br>
4. Right-click -> "Pin to Quick Access".

*Path: `C:\Users\yourname\Projects`*
:::
::: {.os-card}
**ğŸ§ Linux**
1. Open Terminal.<br>
2. Type `mkdir ~/Projects`.<br>
3. You're done.

*Path: `/home/yourname/Projects`*
:::
:::

## 2. The Architecture: Mirrored Roots

Now that you have your locations set, follow the **Mirrored Strategy**. You will have two root folders. They will have **identical sub-folder structures**, but they serve different purposes.

::: {.mirror-container}
<!-- GIT SIDE -->
::: {.mirror-box .git}
::: {.mirror-title}
<span>ğŸ’» ~/Projects</span>
<span style="font-size:0.8em; font-weight:normal; color:#666;">(Local + Git)</span>
:::
::: {.folder-tree}
<!-- Teaching Section -->
<div class="teaching-group">ğŸ“‚ Teaching/</div>
<div style="padding-left: 20px;">ğŸ“‚ ma101_linear_algebra/</div>
<div style="padding-left: 40px;">ğŸ“„ lectures.qmd</div>
<div style="padding-left: 40px;">ğŸ“„ script_week1.R</div>
<div style="padding-left: 40px;">ğŸ“„ _quarto.yml</div>

<br>
<!-- Research Section -->
<div class="research-group">ğŸ“‚ Research/</div>
<div style="padding-left: 20px;">ğŸ“‚ climate_change_paper/</div>
<div style="padding-left: 40px;">ğŸ“„ analysis.ipynb</div>
<div style="padding-left: 40px;">ğŸ“„ manuscript.tex</div>
:::
<p style="margin-top:15px; font-size:0.9rem;"><em><strong>Rule:</strong> Contains Text & Code only. No large
files (>50MB). This is backed up via GitHub.</em></p>
:::

<!-- CLOUD SIDE -->
::: {.mirror-box .cloud}
::: {.mirror-title}
<span>â˜ï¸ ~/OneDrive</span>
<span style="font-size:0.8em; font-weight:normal; color:#666;">(Synced)</span>
:::
::: {.folder-tree}
<!-- Teaching Section -->
<div class="teaching-group">ğŸ“‚ Teaching/</div>
<div style="padding-left: 20px;">ğŸ“‚ ma101_linear_algebra/</div>
<div style="padding-left: 40px;">ğŸ“„ scanned_textbook.pdf</div>
<div style="padding-left: 40px;">ğŸ“„ student_grades.xlsx</div>

<br>
<!-- Research Section -->
<div class="research-group">ğŸ“‚ Research/</div>
<div style="padding-left: 20px;">ğŸ“‚ climate_change_paper/</div>
<div style="padding-left: 40px;">ğŸ“„ raw_weather_data.csv <span class="dim">(2GB)</span></div>
<div style="padding-left: 40px;">ğŸ“„ final_proof.pdf</div>
:::
<p style="margin-top:15px; font-size:0.9rem;"><em><strong>Rule:</strong> Contains Binaries, Data, and PDFs.
Accessible from anywhere (web/phone).</em></p>
:::
:::

## 3. The Automation: One Script to Rule Them All

When you have 10+ active repositories, you cannot manually `git pull` inside every folder. You need a "Master Loop" script.

```bash
#!/bin/bash

# ==============================================================================
# ğŸ”„ ACADEMIC SYNC SCRIPT v3.0 (Dynamic Branch Support)
# ==============================================================================

# ------------------------------------------------------------------------------
# âš™ï¸ CONFIGURATION
# ------------------------------------------------------------------------------
TARGET_DIRS=(
    "$HOME/Projects/Teaching"
    "$HOME/Projects/Research/certest"
    "$HOME/Projects/Website"	
)

# ------------------------------------------------------------------------------
# ğŸ INITIALIZATION
# ------------------------------------------------------------------------------
echo ""
echo "=========================================================="
echo "ğŸ”„ STARTING SYNC: $(date '+%Y-%m-%d %H:%M')"
echo "=========================================================="
echo ""

# Array to store the final report
SUMMARY_REPORT=()
has_errors=false

sync_repo() {
    local repo_path="$1"
    local name=$(basename "$repo_path")
    local status_icon="âœ¨"
    local status_text="Clean (No changes)"
    
    cd "$repo_path" || return
    if [ ! -d ".git" ]; then return; fi

    echo "ğŸ“‚ Processing: $name"

    # Get current branch dynamically
    local current_branch=$(git branch --show-current)
    if [ -z "$current_branch" ]; then
        echo "   âš ï¸  WARNING: Detached HEAD state - skipping."
        SUMMARY_REPORT+=("âš ï¸  $name|Detached HEAD - Skipped")
        return
    fi

    echo "   ğŸŒ¿ Branch: $current_branch"

    # Get start hash to compare later
    local start_hash=$(git rev-parse HEAD)

    # 1. ADD & COMMIT
    git add .
    if ! git diff-index --quiet HEAD --; then
        # Check if this is a feature branch with local changes - prompt for confirmation
        if [ "$current_branch" != "main" ] && [ "$current_branch" != "master" ]; then
            echo -n "   âš ï¸  Feature branch with local changes. Sync '$current_branch'? (y/n): "
            read -r response
            if [[ ! "$response" =~ ^[Yy]([Ee][Ss])?$ ]]; then
                echo "   â­ï¸  Skipped by user."
                SUMMARY_REPORT+=("â­ï¸  $name ($current_branch)|Skipped by User")
                return
            fi
            echo "   âœ… Confirmed. Proceeding with sync..."
        fi
        timestamp=$(date "+%Y-%m-%d %H:%M")
        git commit -m "Auto-Sync: $(hostname) at $timestamp" --quiet
        echo "   ğŸ’¾ Local changes committed."
    fi
    
    # Get hash after commit
    local post_commit_hash=$(git rev-parse HEAD)

    # 2. CHECK IF REMOTE BRANCH EXISTS (auto-push new branches)
    if ! git ls-remote --exit-code --heads origin "$current_branch" &>/dev/null; then
        echo "   ğŸ†• New branch detected - auto-pushing to remote."
        if git push -u origin "$current_branch" --quiet 2>/dev/null; then
            echo "   âœ… New branch pushed to remote."
            SUMMARY_REPORT+=("ğŸ†• $name ($current_branch)|New Branch Pushed")
        else
            echo "   âŒ ERROR: Failed to push new branch."
            SUMMARY_REPORT+=("âŒ $name ($current_branch)|Push Failed")
            has_errors=true
        fi
        return
    fi

    # 3. PULL (REBASE)
    if ! git pull --rebase origin "$current_branch" --quiet 2>/dev/null; then
        echo "   âŒ ERROR: Pull failed (Conflict or network issue)."
        SUMMARY_REPORT+=("âŒ $name ($current_branch)|Merge Conflict - Check Manually")
        has_errors=true
        return
    fi

    # Get hash after pull
    local end_hash=$(git rev-parse HEAD)

    # 4. PUSH
    if ! git push origin "$current_branch" --quiet 2>/dev/null; then
        echo "   âŒ ERROR: Push failed."
        SUMMARY_REPORT+=("âš ï¸  $name ($current_branch)|Push Failed (Internet?)")
        has_errors=true
        return
    fi

    # ---------------------------------------------------------
    # ANALYZE WHAT HAPPENED
    # ---------------------------------------------------------
    # Did we commit locally? (Start != Post_Commit)
    local local_change=false
    if [ "$start_hash" != "$post_commit_hash" ]; then local_change=true; fi

    # Did we download changes? (Post_Commit != End)
    local remote_change=false
    if [ "$post_commit_hash" != "$end_hash" ]; then remote_change=true; fi

    # Determine Final Status Label
    local branch_suffix=""
    if [ "$current_branch" != "main" ] && [ "$current_branch" != "master" ]; then
        branch_suffix=" ($current_branch)"
    fi

    if [ "$local_change" = true ] && [ "$remote_change" = true ]; then
        status_icon="ğŸ”„"
        status_text="Synced (Merged Up & Down)"
        echo "   âœ… Synced."
    elif [ "$local_change" = true ]; then
        status_icon="â¬†ï¸ "
        status_text="Pushed Local Work"
        echo "   âœ… Pushed."
    elif [ "$remote_change" = true ]; then
        status_icon="â¬‡ï¸ "
        status_text="Pulled Remote Updates"
        echo "   âœ… Pulled."
    else
        echo "   ğŸ’¤ No changes."
    fi

    # Add to report array
    SUMMARY_REPORT+=("$status_icon $name$branch_suffix|$status_text")
}

# ------------------------------------------------------------------------------
# ğŸ”„ MAIN LOOP
# ------------------------------------------------------------------------------
for parent in "${TARGET_DIRS[@]}"; do
    if [ -d "$parent" ]; then
        for d in "$parent"/*/; do
            d=${d%/}
            if [ -d "$d" ]; then sync_repo "$d"; fi
        done
    fi
done

# ------------------------------------------------------------------------------
# ğŸ“Š FINAL SUMMARY TABLE
# ------------------------------------------------------------------------------
echo ""
echo "=========================================================="
echo "ğŸ“Š FINAL REPORT"
echo "=========================================================="

# Loop through the report array and format nicely
# We use IFS='|' to split the Name from the Status
IFS="|"
for item in "${SUMMARY_REPORT[@]}"; do
    set -- $item
    # $1 is the Repo Name (with icon), $2 is the Status Text
    printf "%-40s %s\n" "$1" "$2"
done

echo "=========================================================="
if [ "$has_errors" = true ]; then
    echo "âŒ WARNING: Some repos failed. Check the log above."
else
    echo "âœ¨ All repositories are safe and synced."
fi
echo "=========================================================="
```

<a href="files/sync_work.sh" download class="btn btn-primary">
  <i class="bi bi-download"></i> Download Script
</a>

**Mac/Linux Users:** Run `chmod +x sync_work.sh` to make it executable.
**Windows Users:** Install "Git Bash" (included with Git for Windows) to run this script.

## 4. Connecting the Worlds: How to Load Data

Your code is in `~/Projects`, but your data is in `~/OneDrive`. How do you load the data without hardcoding paths that break when you switch computers?

### Method A: For Small Data (Inside Git)

If your data is small (<50MB) and lives **inside** your project folder, use **Project-Relative Paths**. This guarantees your code runs anywhere.

**Using R's `here` package**

```r
library(here) 
# 'here()' automatically finds the root of your Git project
# No more setwd()! 
df <- read.csv(here("data", "small_dataset.csv"))
```

**Using Python's `pyprojroot`**

```python
import pandas as pd
from pyprojroot import here

# Finds the root containing .git, requirements.txt, etc.
# The '/' operator works because here() returns a Path object
data_path = here() / "data" / "small_dataset.csv"
df = pd.read_csv(data_path)
```

### Method B: For Large Data (In OneDrive/Cloud)

For data that lives **outside** the project (in the cloud), paths might differ per machine (e.g., `OneDrive - University` vs `OneDrive - Personal`). The professional solution is **Environment Variables**.

1. Create a hidden file in your Home folder containing the path for *that specific computer*.

**ğŸ“„ .Renviron (Save in your Home folder)**

```bash
# On your Work Computer
CLOUD_DATA_DIR="/Users/admin/OneDrive - University/Research"

# On your Home Computer
CLOUD_DATA_DIR="/Users/john/OneDrive/Research"
```

2. Load it in your code using the variable name. The code remains identical on both machines!

**In R (Automatic Loading)**

```r
# R automatically reads .Renviron on startup
data_root <- Sys.getenv("CLOUD_DATA_DIR")

df <- read.csv(file.path(data_root, "climate_change_paper", "big_data.csv"))
```

**In Python (Using dotenv)**

```python
import os
import pandas as pd
from dotenv import load_dotenv

# Load variables from .env or .Renviron file
load_dotenv() 

data_root = os.getenv("CLOUD_DATA_DIR")
df = pd.read_csv(f"{data_root}/climate_change_paper/big_data.csv")
```

## Summary Checklist

1. **Location:** Move all code to `~/Projects`. Move all docs to `~/OneDrive`.
2. **Structure:** Keep separate folders for `Teaching` and `Research` inside both locations.
3. **Automate:** Run the sync script when you sit down (Pull) and when you stand up (Push).
4. **Paths:** Use `here()` for repo files and `Sys.getenv()` for cloud files.
